{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Kyei7cq0L5pL"
   },
   "source": [
    "**Mapping closure for $f_B$ in 1D using a Monte-Carlo Implementation**\n",
    "\n",
    "This notebook introduces the mapping closure developed by (Chen, H. 1989, Pope, S.B. 1991) and discusses how it can be applied to the problem of turbulent scalar mixing. In contrast to these works which consider a one-point pdf, usually in the context of homogeneous isotropic turbulence, we consider the *global pdf* describing the contents of an arbitrary control volume.\n",
    "\n",
    "\n",
    "**Content**\n",
    "\n",
    "We first import all the packages we need to run this example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "BiVkhX9FL1Ah"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evolution equation for the PDF**\n",
    "\n",
    "Following [Pope et al. 1985](https://www.sciencedirect.com/science/article/abs/pii/0360128585900024) the evolution equation for these distributions is given by\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial F}{\\partial t} = -\\mathbb{E}_Y[ \\Gamma \\nabla^2 Y ] \\frac{\\partial F}{\\partial y},\n",
    "\\end{equation}\n",
    "\n",
    "and\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial f}{\\partial t} = -\\frac{\\partial }{\\partial y} \\left( \\mathbb{E}_Y[ \\Gamma \\nabla^2 Y ] f \\right).\n",
    "\\end{equation}\n",
    "\n",
    "As $f(y,t)$ contains no information about space this equation is unclosed as the conditional expectation is unknown, however we can apply the mapping closure developed by [Pope et al. 1991](https://link.springer.com/article/10.1007/BF00271466) to estimate a closure for the molecular mixing terms.\n",
    "\n",
    "The idea behind this closure relies on Gaussian random fields. What makes these \"random\" fields particularly useful is:\n",
    "- They are completely defined by their mean and covariance: \n",
    "\\begin{equation}\n",
    "    \\mu = \\mathbb{E}[\\theta(\\mathbf{z})], \\quad \\rho(r) = \\mathbb{E}[\\theta(\\mathbf{z})\\theta(\\mathbf{z} + \\mathbf{e}r)] - \\mu^2,\n",
    "\\end{equation}\n",
    "- Allow the calculate explicity the conditional expectation\n",
    "\\begin{equation}\n",
    "lim_{r \\to 0} \\frac{\\partial^2 \\rho(r)}{\\partial r^2} = \\left\\langle \\frac{\\partial \\theta}{\\partial z_i} \\frac{\\partial \\theta}{\\partial z_i} \\right\\rangle,\n",
    "\\end{equation}\n",
    "\n",
    "and the fact that multiple different field can have the same global PDF.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mapping Closure**\n",
    "\n",
    "Based on the properties of the Gaussian random field the idea is therefore to find a mapping \n",
    "\\begin{equation}\n",
    "\\tilde{Y}(\\mathbf{x},t) = \\mathscr{Y}(\\theta(\\mathbf{x} J(t)),t),\n",
    "\\end{equation}\n",
    "such that we can express the CDF $F$ in terms of the cumulative Gaussian $G$ \n",
    "\\begin{equation}\n",
    "F(\\mathscr{Y}(\\eta,t),t) = G(\\eta).\n",
    "\\end{equation}\n",
    "\n",
    "Differentiating the last equation we obtain\n",
    "\\begin{equation}\n",
    "\\frac{ \\partial F}{\\partial t} = -\\frac{ \\partial \\mathscr{Y}}{\\partial t} \\frac{ \\partial F}{\\partial y}.\n",
    "\\end{equation}\n",
    "which can then be expressed as\n",
    "\\begin{equation}\n",
    "\\frac{\\partial \\mathscr{Y}}{\\partial t} = \\mathbb{E}_Y[ \\Gamma \\nabla^2 Y ] = \\Gamma \\underbrace{\\frac{J^2(t)}{\\lambda_{\\theta}^2}}_{= 1/\\tau} \\left( \\frac{\\partial^2 \\mathscr{Y} }{\\partial \\eta^2} - \\eta \\frac{\\partial \\mathscr{Y} }{\\partial \\eta} \\right).\n",
    "\\end{equation}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Particle Implementation**\n",
    "\n",
    "Although we can solve this equation as a PDE on a grid using a standard method such as finite-difference it is also possible to use a particle method. Let $g(\\eta)$ be the PDF of the random variable $\\theta_t$ be generated an Ornstein-Uhlenbeck process:\n",
    "\n",
    "\\begin{equation}\n",
    "  d \\theta_{t} = -\\frac{\\theta_{t}}{T} d t +\\left(\\frac{2}{T} \\right)^{1/2} d W_{t},\n",
    "\\end{equation}\n",
    "\n",
    "and $Y_{t}=\\mathscr{Y}(\\theta_t,t)$, if follows from Ito's lemma implies that\n",
    "\n",
    "\\begin{equation}\n",
    "  d Y_{t} = \\frac{\\partial \\mathscr{Y}_{t} }{\\partial t} dt + \\frac{1}{T} \\left( -\\eta \\frac{\\partial \\mathscr{Y}_{t}}{\\partial \\eta} + \\frac{\\partial^2 \\mathscr{Y}_{t}}{\\partial \\eta^{2}} \\right) dt + \\frac{\\partial \\mathscr{Y}_{t}}{\\partial \\eta} \\left( \\frac{2}{T} \\right)^{1/2} d W_{t},\n",
    "\\end{equation}\n",
    "\n",
    "where $\\eta$ is the sample-space (or dummy) variable corresponding to the random variable $\\theta_t$. Substitution for $\\frac{\\partial \\mathscr{Y}_{t} }{\\partial t}$ then gives the full system as\n",
    "\n",
    "\\begin{align*} \n",
    " d \\theta_{t} &= -\\frac{\\theta_{t}}{T} d t + \\left(\\frac{2}{T} \\right)^{1/2} d W_{t},\\\\\n",
    " d      Y_{t} &= \\left( \\frac{1}{\\tau} + \\frac{1}{T} \\right) \\left( -\\eta \\frac{\\partial \\mathscr{Y}_{t}}{\\partial \\eta} + \\frac{\\partial^2 \\mathscr{Y}_{t}}{\\partial \\eta^{2}} \\right) dt + \\frac{\\partial \\mathscr{Y}_{t}}{\\partial \\eta} \\left( \\frac{2}{T} \\right)^{1/2} d W_{t},\n",
    "\\end{align*}\n",
    "\n",
    "where it is understood that $\\eta$, $\\mathscr{Y}_t(\\eta)$ and its derivatives are to be evaluated at $\\eta = \\theta_t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine $\\mathscr{Y}_t$ and its derivatives requires that $F(\\mathscr{Y}(\\eta,t),t) = G(\\eta)$ is satisfied. Solving for the inverse CDF $F^{-1}(p,t) we can determine\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathscr{Y}(\\eta,t) = F^{-1}( G(\\eta), t),\n",
    "\\end{equation}\n",
    "\n",
    "as a function of $\\eta$. Differentiating $F(\\mathscr{Y}(\\eta,t),t) = G(\\eta)$ then gives \n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial \\mathscr{Y}_{t}}{\\partial \\eta} = \\frac{g(\\eta)}{f(\\mathscr{Y}(\\eta,t),t)},\n",
    "\\end{equation}\n",
    "\n",
    "which differentiated again respect to $\\eta$ gives\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial^2 \\mathscr{Y}_{t}}{\\partial \\eta^2} = - \\eta \\frac{g}{f} - \\frac{g}{f^2} \\frac{\\partial \\mathscr{Y}_{t}}{\\partial \\eta} = - \\frac{g}{f} \\left( \\eta  - \\frac{g}{f^2} \\right),\n",
    "\\end{equation}\n",
    "\n",
    "an expression that is a function of $g, f$ and $\\eta$ only. However, as the system depends on the global PDF at each time-step it corresponds to a McKean-Vlasov equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from KDEpy import FFTKDE\n",
    "\n",
    "# def Y_map_KDE(data_x,data_y):\n",
    "#     \"\"\"\n",
    "#     Calculates E[Y|X=x] = int f_Y|X(y|x)*y dy = int f_XY(x,y)*y dy / f_X(x)\n",
    "#     \"\"\"\n",
    "#     # Grid points in the x and y direction\n",
    "#     grid_points_x, grid_points_y = 2**8, 2**8\n",
    "\n",
    "#     # Stack the data for 2D input, compute the KDE\n",
    "#     data = np.vstack((data_x, data_y)).T\n",
    "#     kde = FFTKDE(kernel='gaussian', bw=.1).fit(data)\n",
    "#     grid, points = kde.evaluate((grid_points_x, grid_points_y))\n",
    "\n",
    "#     # Retrieve grid values, reshape output and plot boundaries\n",
    "#     x, y = np.unique(grid[:, 0]), np.unique(grid[:, 1])\n",
    "#     f_XY = points.reshape(grid_points_x, grid_points_y)\n",
    "    \n",
    "#     EY_cX =  np.sum(  (f_XY.T / np.sum(f_XY, axis=1) ).T  * y , axis=1)\n",
    "\n",
    "#     return EY_cX, x\n",
    "\n",
    "def inverse_cdf(X, p):\n",
    "    \"\"\"\n",
    "    Compute the inverse CDF (quantile function) for a given dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    - X: numpy array of float values\n",
    "    - p: array of probabilities for which to compute the quantile function\n",
    "    \n",
    "    Returns:\n",
    "    - quantiles: values corresponding to the given probabilities\n",
    "    \"\"\"\n",
    "    x = np.sort(X)  # Sort data for empirical CDF\n",
    "    n = len(x)\n",
    "    \n",
    "    # Create an empirical CDF\n",
    "    F = np.linspace(1/n, 1, n)  # Avoid zero probability\n",
    "    \n",
    "    # Interpolate to get the quantiles\n",
    "    return np.interp(x=p, xp=F, fp=x)\n",
    "\n",
    "def Y_map(Y, θ, N=32):\n",
    "    \"\"\"\n",
    "    Calculates f, η, Y, dY, ddY\n",
    "    \"\"\"\n",
    "\n",
    "    # PDFs\n",
    "    f, y  = np.histogram(Y, bins=N, density=True)\n",
    "    g, η  = np.histogram(θ, bins=N, density=True)\n",
    "    \n",
    "    # CDFs\n",
    "    F = np.cumsum(f) \n",
    "    F /= F[-1] \n",
    "    G = np.cumsum(g) \n",
    "    G /= G[-1] \n",
    "\n",
    "    # Inverse CDF\n",
    "    Q = inverse_cdf(data, probabilities)\n",
    "\n",
    "\n",
    "    return f, η, Y, dY, ddY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from   scipy.stats import gaussian_kde, norm\n",
    "from derivatives import grad,laplacian\n",
    "\n",
    "# Parameters\n",
    "num_particles = 10**3  # Number of Monte Carlo samples\n",
    "num_steps = 10     # Time steps\n",
    "dt = 0.01         # Time step size\n",
    "T  = 1\n",
    "τ  = 1\n",
    "\n",
    "Y_min = -2\n",
    "Y_max =  2\n",
    "\n",
    "# Brownian increments\n",
    "dW_t = np.sqrt(dt) * norm.rvs(loc=0, scale=1, size=(num_particles, num_steps, 2))  \n",
    "\n",
    "# Container\n",
    "θ = np.zeros((num_particles, num_steps))\n",
    "Y = np.zeros((num_particles, num_steps))\n",
    "\n",
    "# Initial conditions\n",
    "θ[:,0] = np.random.normal(0, 1, num_particles)  # Initial condition (Normal distribution)\n",
    "\n",
    "Y[:,0] = np.random.normal(0, 1, num_particles)  \n",
    "\n",
    "# Half of the particles to +1 and the other to -1\n",
    "#Y[:num_particles//2,0] = 1\n",
    "#Y[num_particles//2:,0] =-1\n",
    "\n",
    "f, η, Y, dY, ddY = \n",
    "\n",
    "# Euler Maruyama\n",
    "for n in range(1, num_steps):\n",
    "\n",
    "    # if n%(num_steps // 10) == 0:\n",
    "    #     plt.plot(η, EY_cη, 'k')\n",
    "    #     plt.show()\n",
    "    #     plt.hist(Y[:, n-1], bins=50, density=True, alpha=0.6)\n",
    "    #     #plt.xlim([-1.1, 1.1])\n",
    "    #     plt.show()\n",
    "\n",
    "    # Calculate Y via joint pdf O(num_particles*n_bins) ??\n",
    "    f, η, Y, dY, ddY = \n",
    "\n",
    "    # Update particles\n",
    "    θ[:, n] = θ[:, n-1] -  (      1/T) * (         θ[:, n-1]) * dt +    np.sqrt(2/T) * dW_t[:,n-1,0]\n",
    "    Y[:, n] = Y[:, n-1] +  (1/τ + 1/T) * (ddY - dY*θ[:, n-1]) * dt + dY*np.sqrt(2/τ) * dW_t[:,n-1,1]\n",
    "\n",
    "    # Apply Reflecting/bcs\n",
    "    # Y[:, n] = np.where(Y[:, n] > Y_max, Y_max - (Y[:, n] - Y_max), Y[:, n]) # Reflect back inside\n",
    "    # Y[:, n] = np.where(Y[:, n] < Y_min, Y_min + (Y_min - Y[:, n]), Y[:, n]) # Reflect back inside\n",
    "\n",
    "\n",
    "# # Estimate the probability density function at final time step using KDE\n",
    "# b_values = np.linspace(-1.2, 1.2, 100)\n",
    "# kde = gaussian_kde(b[:, -1])\n",
    "# pdf_values = kde(b_values)\n",
    "\n",
    "# # Plot the Monte Carlo histogram and estimated density\n",
    "# plt.figure(figsize=(8, 5))\n",
    "# plt.hist(b[:, -1], bins=50, density=True, alpha=0.6, label=\"Monte Carlo Histogram\")\n",
    "# plt.plot(b_values, pdf_values, 'r-', label=\"Kernel Density Estimation (KDE)\")\n",
    "# plt.xlabel(\"x\")\n",
    "# plt.ylabel(\"Probability Density\")\n",
    "# plt.title(\"Monte Carlo Solution of Fokker-Planck\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "dedalus3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "589404f707e0e92b82b1f57c0985e6f96586f8fb1352342a2d336ffc2faa31c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
